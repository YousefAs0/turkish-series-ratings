name: Daily TİAK Scraper

on:
  schedule:
    - cron: '0 9 * * *'
    - cron: '0 11 * * *'
  workflow_dispatch:

jobs:
  scrape_and_sync:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      issues: write
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Dependencies
        run: |
          pip install requests beautifulsoup4 playwright
          playwright install chromium

      - name: Run Scraper
        env:
          API_URL: ${{ secrets.API_URL }}
          API_TOKEN: ${{ secrets.API_TOKEN }}
        run: python .github/workflows/scraper.py

      - name: Run Twitter Bot
        env:
          X_API_KEY: ${{ secrets.X_API_KEY }}
          X_API_SECRET: ${{ secrets.X_API_SECRET }}
          X_ACCESS_TOKEN: ${{ secrets.X_ACCESS_TOKEN }}
          X_ACCESS_SECRET: ${{ secrets.X_ACCESS_SECRET }}
          TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
        run: python twitter.py

      - name: Commit and Push Changes
        if: success()
        run: |
          git config --global user.name "Scraper Bot"
          git config --global user.email "bot@turkish-ratings.com"
          git add data/*.json
          git commit -m "Auto-archive: $(date +'%Y-%m-%d')" || exit 0
          git push

      - name: Trigger TMDB Sync
        if: success()
        run: |
          curl -s "${{ secrets.TMDB_SYNC_URL }}"

      - name: Notify on Failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '❌ Scraper Engine Failure: ' + new Date().toISOString().split('T')[0],
              body: 'Daily TİAK scraper failed. Check logs: https://github.com/' + context.repo.owner + '/' + context.repo.repo + '/actions/runs/' + context.runId
            })
